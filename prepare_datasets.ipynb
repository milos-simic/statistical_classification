{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare  datasets <a class=\"tocSkip\">\n",
    "\n",
    "In this notebook, we create three datasets: $\\mathcal{E}$ and $\\mathcal{D}$ that contain samples from various normal and non-normal distributions, and $\\mathcal{C}$ which contains samples from non-normal distributions on which statisticians usually estimate power of standard statistical tests of normality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:49:09.488114Z",
     "start_time": "2020-10-21T01:49:01.031361Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the data directory path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T02:48:37.078539Z",
     "start_time": "2020-10-17T02:48:37.069432Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the path to the directory to which the datasets will be stored\n",
    "data_directory_path = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{E}$\n",
    "\n",
    "The samples consist of $10, 20, \\ldots, 100$ elements. \n",
    "\n",
    "The normal samples are drawn from a a normal distributions $N(\\mu,\\sigma^2)$ whose location parameter ($\\mu$) is randomly selected from the range $[-100,100]$ and the standard deviation is randomly drawn from the range $[1, 20]$. For each $n$, a total of $6525$ normal distributions are defined and a sample of size $n$ is drawn from each of them.\n",
    "\n",
    "The non-normal samples are drawn from the Pearson family of distributions. Each distribution is specified by its first four moments. The mean and standard deviation are determined the same as for the normal samples. They are combined with the skewness ($s$) and kurtosis ($k$) that range over $\\{\\}$ and $\\{\\}$ and fulfill the following two conditions: (1) $k - s^2 - 1 \\geq 0$ and (2) $\\neg(s=0 \\land k=3)$. The first condition is a limitation known from theory. The second requirement is there to ensure that those non-normal distributions are sufficiently different from the normal ones, since for normal distributions it holds that $s = 0$ and $k = 3$. A sample is drawn from each such distribution.\n",
    "\n",
    "The set is balanced. It contains $65250$ normal and $65250$ non-normal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:49:12.691983Z",
     "start_time": "2020-10-21T01:49:12.680080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis in the set A\n",
    "n_range = range(10, 101, 10)\n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -300, 301, 5;-150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 401, 5;0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution.\n",
    "# Since the set is created as balanced, M will influence the number of normal samples\n",
    "# in the set. See the function generate_dataset for details.\n",
    "M = 5\n",
    "\n",
    "# Create a function that generates datasets\n",
    "def generate_dataset(n_range, s_range, k_range, M, verbose=True):\n",
    "    # Generate non-normal samples\n",
    "    nonnormal_samples = util.generate_pearson_nonnormal_samples(s_range, k_range, n_range, M)\n",
    "\n",
    "    # Calculate L, the number of normal samples of the same size\n",
    "    L = len(nonnormal_samples) // len(n_range)\n",
    "            \n",
    "    # Generate L normal samples of size n for each n in n_range\n",
    "    normal_samples = util.generate_normal_samples(n_range, L)\n",
    "\n",
    "    # Print how many samples were generated\n",
    "    if verbose:\n",
    "        print(\"Normal samples: \", len(normal_samples))\n",
    "        print(\"Non-normal samples: \", len(nonnormal_samples))\n",
    "\n",
    "    # Label the sets\n",
    "    normal_samples = util.label_samples(normal_samples, 1)\n",
    "    nonnormal_samples = util.label_samples(nonnormal_samples, 0)\n",
    "\n",
    "    # Unify them\n",
    "    all_samples = normal_samples + nonnormal_samples\n",
    "    \n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T03:02:29.845867Z",
     "start_time": "2020-10-17T03:01:44.143321Z"
    }
   },
   "outputs": [],
   "source": [
    "set_E = generate_dataset(n_range, s_range, k_range, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-23T23:45:25.287504Z",
     "start_time": "2020-09-23T23:45:23.988568Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.path.join(data_directory_path, '{}.data'.format(set_name))\n",
    "util.save_to_file(all_samples, path)\n",
    "print(\"Saved to the file\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{C}$\n",
    "\n",
    "This set contains non-normal samples whose sizes are $10, 20, \\ldots, 100$.\n",
    "\n",
    "The non-normal distributions from which the samples are drawn are hand-picked and are usually used to assess the empirical power of normality tests. They are clssified into four groups. $G_1, G_2, G_3$ and $G_4$. See the paper for more details. For each sample size $n \\in \\left\\{10, 20, \\ldots, 100\\right\\}$, $L=10000$ samples are drawn from each group.\n",
    "\n",
    "Define the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T05:08:25.125519Z",
     "start_time": "2020-10-17T05:08:25.111375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the distributions from group G1\n",
    "logistic = lambda n: stats.logistic.rvs(size = n)\n",
    "laplace = lambda n: stats.laplace.rvs(size = n)\n",
    "t1 = lambda n: stats.t.rvs(1, size = n)\n",
    "t3 = lambda n: stats.t.rvs(3, size = n)\n",
    "\n",
    "# Define the distributions from group G2\n",
    "gumbel1 = lambda n: list(np.random.gumbel(loc=0, scale=1, size=n))\n",
    "gumbel2 = lambda n: list(np.random.gumbel(loc=0, scale=2, size=n))\n",
    "gumbel3 = lambda n: list(np.random.gumbel(loc=0, scale=0.5, size=n))\n",
    "\n",
    "# Define the distributions from group G3\n",
    "expon = lambda n: stats.expon.rvs(loc = 1, size = n)\n",
    "gamma1 = lambda n: list(np.random.gamma(2, scale = 1, size = n))\n",
    "gamma2 = lambda n: list(np.random.gamma(0.5, scale = 1, size = n))\n",
    "lognormal1 = lambda n: list(np.random.lognormal(mean = 0, sigma = 1, size = n))\n",
    "lognormal2 = lambda n: list(np.random.lognormal(mean = 0, sigma = 2, size = n))\n",
    "lognormal3 = lambda n: list(np.random.lognormal(mean = 0, sigma = 0.5, size = n))\n",
    "weibull1 = lambda n: stats.weibull_min.rvs(0.5, scale = 1, size = n)\n",
    "weibull2 = lambda n: stats.weibull_min.rvs(2, scale = 1, size = n)\n",
    "\n",
    "# Define the distributions from group G4\n",
    "uniform = lambda n: list(np.random.uniform(low = 0, high = 1, size = n))\n",
    "beta1 = lambda n: np.random.beta(2, 2, size = n)\n",
    "beta2 = lambda n: np.random.beta(0.5, 0.5, size = n)\n",
    "beta3 = lambda n: np.random.beta(3, 1.5, size = n)\n",
    "beta4 = lambda n: np.random.beta(2, 1, size = n)\n",
    "\n",
    "# Let groups be a dictionary containing distributions from four groups G1-G4\n",
    "groups = {\n",
    "    1 : [logistic, laplace, t1, t3],\n",
    "    2 : [gumbel1, gumbel2, gumbel3],\n",
    "    3 : [expon, gamma1, gamma2, lognormal1, lognormal2, lognormal3, weibull1, weibull2],\n",
    "    4 : [uniform, beta1, beta2, beta3, beta4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and save the samples from the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T05:09:45.806658Z",
     "start_time": "2020-10-17T05:09:20.520672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the range of sample sizes\n",
    "n_range = range(10, 101, 10)\n",
    "\n",
    "# Define L, which denotes how many samples with n elements\n",
    "# will be drawn from each group.\n",
    "L = 10000\n",
    "\n",
    "set_C = {}\n",
    "\n",
    "for g in groups:\n",
    "    # Select a group\n",
    "    group = groups[g]\n",
    "    \n",
    "    # Prepare the storage to hold the samples from this group\n",
    "    samples = []\n",
    "    \n",
    "    # Draw the samples\n",
    "    for n in n_range:\n",
    "        # Initialize the counter of the samples generated so far in this group\n",
    "        so_far = 0\n",
    "        \n",
    "        # Iterate over the distributions in the group until L samples are generated\n",
    "        d = 0\n",
    "        while so_far <= L:\n",
    "            # Get the distribution whose turn is to generate a sample\n",
    "            dist = group[d]\n",
    "            \n",
    "            # Generate a sample\n",
    "            sample = dist(n)\n",
    "            \n",
    "            # Store it\n",
    "            samples.append(sample)\n",
    "            \n",
    "            # Increase the counters\n",
    "            so_far = so_far + 1\n",
    "            d = d + 1\n",
    "            \n",
    "            # Return to the first distribution in the group and start over\n",
    "            if d == len(group):\n",
    "                d = 0\n",
    "    \n",
    "    # Label the samples as non-normal\n",
    "    samples = util.label_samples(samples, 0)\n",
    "    \n",
    "    # Describe the set\n",
    "    set_name = 'C-G{}'.format(g)\n",
    "    filename = '{}.data'.format(set_name)\n",
    "    \n",
    "    path = os.path.join(data_directory_path, filename)\n",
    "                \n",
    "    # Save the samples\n",
    "    util.save_to_file(samples, path)\n",
    "    print(\"Saved {} to the file {}\".format(set_name, path))\n",
    "    \n",
    "    set_C[set_name] = samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set $\\mathcal{D}$\n",
    "\n",
    "Same as $\\mathcal{E}$, but with fewer samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:49:27.018701Z",
     "start_time": "2020-10-21T01:49:17.437529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the ranges for the sample sizes \n",
    "# and non-normal skewness and kurtosis \n",
    "n_range = range(10, 101, 10)\n",
    "s_range = [x/10.0 for x in range(-300, 301, 5)] # skewness range -150, 151, 5;-805, 810, 5\n",
    "k_range = [x/10.0 for x in range(0, 401, 5)]   # kurtosis range 0, 201, 5;0, 1610, 5\n",
    "\n",
    "# Let M denote the number of non-normal samples drawn from the same distribution.\n",
    "# Since the set is created as balanced, M will influence the number of normal samples\n",
    "# in the set. See the function generate_dataset for details.\n",
    "M = 1\n",
    "\n",
    "# Generate and save the set\n",
    "set_D = generate_dataset(n_range, s_range, k_range, M)\n",
    "\n",
    "path = os.path.join('data', 'D.data')\n",
    "util.save_to_file(set_D, path)\n",
    "print(\"Saved to the file\", path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3normal",
   "language": "python",
   "name": "p3normal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
