{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Derive Statistical Tests from the Descriptor-Based Neural Network Classifier <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:02:39.933898Z",
     "start_time": "2020-10-20T23:02:30.513423Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import everything that's needed to run the notebook\n",
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "import datetime\n",
    "import random\n",
    "import datetime as dt\n",
    "\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "from scipy.stats import shapiro\n",
    "import matplotlib.pyplot as plt\n",
    "import boruta\n",
    "from scipy.stats import gaussian_kde\n",
    "import warnings\n",
    "\n",
    "import util\n",
    "from util import DescriptorBuilder, prepare_input, traverse_and_save\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary to store the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:02:39.937961Z",
     "start_time": "2020-10-20T23:02:39.935598Z"
    }
   },
   "outputs": [],
   "source": [
    "reports = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:02:40.105660Z",
     "start_time": "2020-10-20T23:02:39.939446Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join('dbnn_classifier.p'), 'rb') as f:\n",
    "    dbnn = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:02:58.697519Z",
     "start_time": "2020-10-20T23:02:40.111588Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the dictionary to store the actual datasets, indexed by their names\n",
    "datasets = {}\n",
    "\n",
    "set_names = ['E', 'D', 'C-G1', 'C-G2', 'C-G3', 'C-G4']\n",
    "\n",
    "# Load the datasets\n",
    "for set_name in set_names: #configuration['data']['datasets']:\n",
    "    set_path = os.path.join('data', set_name + '.data')\n",
    "    print('Loading {} from {}'.format(set_name, set_path))\n",
    "    datasets[set_name] = util.load_from_file(set_path)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the labels from the samples to ease future manipulation. Split $\\mathcal{E}$ into two equal parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:03:52.160770Z",
     "start_time": "2020-10-20T23:03:51.590354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chosen_sets = list(datasets.keys())\n",
    "\n",
    "for set_name in chosen_sets:\n",
    "    labels = [sample.pop() for sample in datasets[set_name]]\n",
    "    samples = datasets[set_name]\n",
    "    \n",
    "    if set_name == 'E':\n",
    "        stratify = [str(label) + str(len(sample)) for (label, sample) in zip(labels, samples)]\n",
    "        samples_1, samples_2, labels_1, labels_2 = train_test_split(samples, labels, train_size=0.5, stratify=stratify)\n",
    "        datasets['E1'] = {'samples' : samples_1, 'labels' : labels_1}\n",
    "        datasets['E2'] = {'samples' : samples_2, 'labels' : labels_2}\n",
    "    else:\n",
    "        datasets[set_name] = {'samples' : samples, 'labels' : labels}\n",
    "    \n",
    "del datasets['E']\n",
    "\n",
    "chosen_sets = list(datasets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T10:51:21.567469Z",
     "start_time": "2020-08-19T10:51:21.485443Z"
    }
   },
   "source": [
    "## Define the Statistic\n",
    "Define the statistic as the net's final layer's output. Refer to the statistic as $T$ from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:03:58.813541Z",
     "start_time": "2020-10-20T23:03:58.808802Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dbnn_statistic_function(samples):\n",
    "    prepared_samples = prepare_input(samples, dbnn)\n",
    "    activations = util.get_activations(dbnn['neural_net'], prepared_samples)\n",
    "    return activations[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Statistic's Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define a function that performs visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:04:05.782917Z",
     "start_time": "2020-10-20T23:04:05.775785Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_statistics(samples, labels, statistic_function, xlim=None, ylim=None, \n",
    "                         colors=['crimson', 'navy'], ylabel='density', xlabel='Statistic'):\n",
    "    results = pd.DataFrame({\n",
    "        'n' : [len(sample) for sample in samples],\n",
    "        'label' : [int(label) for label in labels],\n",
    "        'statistic' : statistic_function(samples).ravel(),\n",
    "    })\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    if xlim is not None:\n",
    "        plt.xlim(*xlim)\n",
    "    \n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "\n",
    "    for label in [0, 1]:\n",
    "        mask = (results['label'] == label)\n",
    "        results[mask]['statistic'].plot(kind='density', label='$f_{}$'.format(label),\n",
    "                                      color=colors[label], linewidth=5)\n",
    "\n",
    "    plt.ylabel(ylabel, fontsize=25)\n",
    "    plt.xlabel(xlabel, fontsize=25)\n",
    "    plt.legend(fontsize=25)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:27:09.751448Z",
     "start_time": "2020-10-16T03:26:59.423947Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = visualize_statistics(datasets['E1']['samples'],\n",
    "                           datasets['E1']['labels'],\n",
    "                           dbnn_statistic_function, xlim=(0, 1),\n",
    "                           xlabel='$T$', ylabel='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the figure so that we can save it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:27:20.427313Z",
     "start_time": "2020-10-16T03:27:20.424744Z"
    }
   },
   "outputs": [],
   "source": [
    "reports['T_statistic_fig'] = fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the  Tests\n",
    "\n",
    "Define the basic class of the binary tests. Its main functionalities are the methods for calculating the $p$-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:09:12.426333Z",
     "start_time": "2020-10-20T23:09:12.406253Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class OneStatisticTest(object):\n",
    "    def __init__(self, samples, statistic_function, lower_is_more_extreme=True, adapt_to_size=False):\n",
    "        super(OneStatisticTest, self).__init__()\n",
    "        self.statistic_function = statistic_function\n",
    "        self.statistics = np.sort(statistic_function(samples)).squeeze()\n",
    "        self.lower_is_more_extreme = lower_is_more_extreme\n",
    "        self.adapt_to_size = adapt_to_size\n",
    "        \n",
    "        if adapt_to_size:\n",
    "            sizes = np.array([len(sample) for sample in samples])\n",
    "            self.__prepare_statistics_by_sample_size(self.statistics, sizes)\n",
    "        \n",
    "    def __prepare_statistics_by_sample_size(self, statistics, sizes):\n",
    "        by_sample_size = {}\n",
    "        for size in np.unique(sizes):\n",
    "            selected_statistics = statistics[sizes == size].squeeze()\n",
    "            by_sample_size[size] = np.sort(selected_statistics).squeeze()\n",
    "        self.statistics_by_size = by_sample_size \n",
    "    \n",
    "    def p_value(self, sample):\n",
    "        [sample_statistic] = self.statistic_function([sample])\n",
    "        \n",
    "        n = len(sample)\n",
    "        \n",
    "        if self.adapt_to_size == False or n not in self.statistics_by_size.keys():\n",
    "            statistics = self.statistics\n",
    "        else:\n",
    "            statistics = self.statistics_by_size[n]\n",
    "        \n",
    "        total_count = len(statistics)\n",
    "        \n",
    "        if self.lower_is_more_extreme:\n",
    "            [i] = np.searchsorted(statistics, sample_statistic, side='right')\n",
    "            more_extreme_count = i\n",
    "        else:\n",
    "            [i] = np.searchsorted(statistics, sample_statistic, side='left')\n",
    "            more_extreme_count = total_count - i + 1\n",
    "\n",
    "        return more_extreme_count / total_count\n",
    "    \n",
    "    def calculate_statistic(self, sample):\n",
    "        return self.statistic_function([sample])\n",
    "    \n",
    "    def quantify_uncertainty(self, sample):\n",
    "        return self.p_value(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:09:21.826398Z",
     "start_time": "2020-10-20T23:09:13.191622Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(datasets['E1']['samples'])\n",
    "normal_samples = [datasets['E1']['samples'][i] for i in range(n) if datasets['E1']['labels'][i] == 1]\n",
    "nonnormal_samples = [datasets['E1']['samples'][i] for i in range(n) if datasets['E1']['labels'][i] == 0]\n",
    "\n",
    "nn_test_1 = OneStatisticTest(normal_samples, dbnn_statistic_function, adapt_to_size=True)\n",
    "nn_test_0 = OneStatisticTest(nonnormal_samples, dbnn_statistic_function, lower_is_more_extreme=False, adapt_to_size=True)\n",
    "\n",
    "nn_tests = [nn_test_0, nn_test_1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T01:31:29.629699Z",
     "start_time": "2020-08-19T01:31:29.623140Z"
    }
   },
   "source": [
    "### Inspect the $p$-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T01:47:24.652333Z",
     "start_time": "2020-08-20T01:47:24.646401Z"
    }
   },
   "source": [
    "The $p$-values are calculated using the set $\\mathcal{E}_1$. We can check their properties using the set $\\mathcal{E}_2$. Those properties are:\n",
    "- The types of their distributions over normal and non-normal samples.\n",
    "- Boundedness from above for the samples from the same distribution for which the $p$ value is calculated. More specifically:\n",
    "$$P\\left(p_c(T(\\mathbf{x}) \\leq \\alpha \\right) \\leq \\alpha \\qquad 0 \\leq \\alpha \\leq 1,\\quad y(\\mathbf{x})=c,\\quad c \\in\\{0,1\\}$$ *Note: The probability $P$ should be interpreted in the frequentist sense, as the long-term frequency*.\n",
    "- Asymptotically decreasing to zero for the samples from the opposite class as the sample size grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Relationship between the $p$-values and Statistics\n",
    "\n",
    "Check the distributions of the $p$-values for normal and non-normal samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the statistics of normal from those of non-normal samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:10:08.752684Z",
     "start_time": "2020-10-20T23:10:08.718522Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e2_separated = util.separate_by_label(datasets['E2']['samples'], datasets['E2']['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the distribution of the $p_c$-values over normal and non-normal statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:44:43.305947Z",
     "start_time": "2020-10-16T02:44:43.113131Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_the_pvalue_density(tests, separated_samples,\n",
    "                                xlabel='Statistic', ylabel=None, \n",
    "                                xlim=None, colors=['crimson', 'navy']):\n",
    "    figs = [None, None]\n",
    "    for c in [0, 1]:\n",
    "        figs[c] = plt.figure(figsize=(10, 8))\n",
    "        plt.xlabel(xlabel, fontsize=16)\n",
    "        if xlim is not None:\n",
    "            plt.xlim(*xlim)\n",
    "    \n",
    "        p_values_normal = [tests[c].p_value(x) for x in separated_samples[1]]\n",
    "        p_values_nonnormal = [tests[c].p_value(x) for x in separated_samples[0]]\n",
    "    \n",
    "        df = pd.DataFrame({'$c={0}$': p_values_nonnormal})\n",
    "        df['$c={0}$'].plot(kind='density', color=colors[0], linewidth=3)\n",
    "        \n",
    "        df = pd.DataFrame({'$c={1}$': p_values_normal})\n",
    "        df['$c={1}$'].plot(kind='density', color=colors[1], linewidth=3)\n",
    "        \n",
    "        if ylabel is None:\n",
    "            ylabel = 'The density of $p_{}$'.format(c)\n",
    "        \n",
    "        plt.ylabel(ylabel, fontsize=16)\n",
    "        \n",
    "        plt.legend(fontsize=16)\n",
    "        \n",
    "    \n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:13.923062Z",
     "start_time": "2020-10-16T02:44:43.307133Z"
    }
   },
   "outputs": [],
   "source": [
    "[fig_0, fig_1] = visualize_the_pvalue_density(fisher_tests, e2_separated,\n",
    "                                              xlabel='$T$', ylabel='density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:51:13.927537Z",
     "start_time": "2020-10-16T02:51:13.925447Z"
    }
   },
   "outputs": [],
   "source": [
    "reports['p0_value_distribution_fig'] = fig_0\n",
    "reports['p1_value_distribution_fig'] = fig_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the $p_1$-value is distributed approximately uniformly over $[0, 1]$ for the normal samples, whereas most of its distribution for the non-normal samples is located in the neighborhood of $0$, as it should be. The analogous conclusion holds for the $p_0$-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Boundedness Condition\n",
    "\n",
    "First, define a function that checks the boundedness of the $p_c$ - value ($c=0,1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:29:14.983325Z",
     "start_time": "2020-10-20T23:29:14.966902Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_boundedness(tests, separated_samples, colors=['crimson', 'navy'], alpha_granularity=100,\n",
    "                     subsets=None, subset_size=50, subset_colors=['mistyrose', 'lavender']):\n",
    "    alphas = np.linspace(0, 1, alpha_granularity)\n",
    "\n",
    "    colors = {0: 'crimson', 1: 'navy'}\n",
    "    \n",
    "    figs = [None, None]\n",
    "    for c in [0, 1]:\n",
    "        #line_label = r'$\\alpha \\mapsto P_{}\\left(\\hat{{p}}_{}(X) \\leq \\alpha \\mid Y = {}\\right)$'.format(c, c, c)\n",
    "        figs[c] = plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        plt.tick_params(axis='both', which='major', labelsize=16)\n",
    "        #plt.plot(alphas, alphas, linewidth=3, linestyle='--', color='black', \n",
    "        #         zorder=2, label=r'$\\alpha \\mapsto \\alpha$')\n",
    "        \n",
    "        plt.xlabel(r'$\\alpha$', fontsize=25)\n",
    "        if c == 0:\n",
    "            plt.ylabel('$FPR$', fontsize=25)\n",
    "        else:\n",
    "            plt.ylabel('$FNR$', fontsize=25)\n",
    "    \n",
    "        p_values = [tests[c].p_value(x) for x in separated_samples[c]]\n",
    "        #density = gaussian_kde(p_values)\n",
    "    \n",
    "        probabilities = []\n",
    "        for alpha in alphas:\n",
    "            prob = len([pval for pval in p_values if pval <= alpha]) / len(p_values)\n",
    "            probabilities.append(prob)\n",
    "            #probabilities.append(density.integrate_box_1d(0, alpha))\n",
    "        \n",
    "        #print(c, probabilities)\n",
    "    \n",
    "        plt.plot(alphas, probabilities, linewidth=3, color=colors[c], zorder=3)\n",
    "    \n",
    "        #plt.legend(fontsize=25)\n",
    "\n",
    "        if subsets is not None:\n",
    "            for i in range(subsets):\n",
    "                n = len(separated_samples[c])\n",
    "                m = subset_size\n",
    "                chosen_samples = [separated_samples[c][j] for j in np.random.choice(n, m, replace=False)]\n",
    "                p_values = [tests[c].p_value(x) for x in chosen_samples]\n",
    "            \n",
    "                probabilities = []\n",
    "                for alpha in alphas:\n",
    "                    prob = len([pval for pval in p_values if pval <= alpha]) / len(p_values)\n",
    "                    probabilities.append(prob)\n",
    "                    \n",
    "                plt.plot(alphas, probabilities, linewidth=2, color=subset_colors[c], zorder=1)\n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:32:35.388736Z",
     "start_time": "2020-10-20T23:29:15.851994Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figs = check_boundedness(nn_tests, e2_separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:32:43.877287Z",
     "start_time": "2020-10-20T23:32:43.871442Z"
    }
   },
   "outputs": [],
   "source": [
    "reports['p0_value_uniform_fig'] = figs[0]\n",
    "reports['p1_value_uniform_fig'] = figs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check boundedness for each sample size $n=10,20,\\ldots, 100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:54:35.690024Z",
     "start_time": "2020-10-16T02:54:35.598888Z"
    }
   },
   "outputs": [],
   "source": [
    "by_label_and_size = {}\n",
    "for c in e2_separated:\n",
    "    by_label_and_size[c] = util.separate_by_size(e2_separated[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T02:59:40.251777Z",
     "start_time": "2020-10-16T02:54:35.691482Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(10, 101, 10):\n",
    "    size_n_e2 = {c : by_label_and_size[c][n] for c in [0, 1]}\n",
    "    check_boundedness(nn_tests, size_n_e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the boundedness condition is fulfilled. This means that the $p_0$ and $p_1$ values can be used to control the overall error rates of the classifiers\n",
    "$$\\begin{cases}0,& p_1 \\leq \\alpha\\\\ 1,& p_1 > \\alpha \\end{cases}\\qquad \\alpha \\in [0, 1]$$ and\n",
    "$$\\begin{cases}1,& p_0 \\leq \\beta\\\\ 0,& p_0 > \\beta \\end{cases}\\qquad \\beta \\in [0, 1]$$\n",
    "respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Asymptotic Behavior\n",
    "\n",
    "Check if the $p_c$-values gather around zero for the samples of the opposite class ($1-c$) as the sample size grows. Use the estimates of $P(p_c \\leq \\varepsilon)$ to quantify the degree to which the $p_c$-values are concentrated in the neighborhood of $0$ when calculated for the samples of the opposite class ($1-c$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:22:47.714124Z",
     "start_time": "2020-10-16T03:22:47.708005Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:33:17.019390Z",
     "start_time": "2020-10-20T23:33:16.998945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def check_asymptotic_behavior(tests, samples, labels, epsilon=0.05,\n",
    "                              number_of_subsets=10, subset_relative_size=0.1,\n",
    "                             colors=['crimson', 'navy']):\n",
    "    probabilities = {}\n",
    "    \n",
    "    sample_groups = util.separate_by_label(samples, labels)\n",
    "    for label in sample_groups:\n",
    "        sample_groups[label] = util.separate_by_size(sample_groups[label])\n",
    "    \n",
    "    for c in [0, 1]:\n",
    "        probabilities[c] = {}\n",
    "        \n",
    "        for size in sample_groups[c]:\n",
    "            probabilities[c][size] = []\n",
    "            group = sample_groups[1 - c][size]\n",
    "            \n",
    "            for i in range(number_of_subsets):\n",
    "                if number_of_subsets == 1:\n",
    "                    chosen_samples = group\n",
    "                    n = len(group)\n",
    "                else:\n",
    "                    n = int(subset_relative_size * len(group))\n",
    "                    chosen_samples = [group[j] for j in np.random.choice(len(group), n, replace=False)]\n",
    "            \n",
    "                p_values = [tests[c].p_value(x) for x in chosen_samples]\n",
    "            \n",
    "                number_of_lower = len([p_val for p_val in p_values if p_val <= epsilon])\n",
    "                prob = number_of_lower / n\n",
    "            \n",
    "                #density = gaussian_kde(p_values)\n",
    "                #prob = density.integrate_box_1d(0, epsilon)\n",
    "                \n",
    "                probabilities[c][size].append(prob)\n",
    "    \n",
    "    figs = [None, None]\n",
    "    for c in probabilities:\n",
    "        sample_sizes = sorted(list(probabilities[c].keys()))\n",
    "        df = pd.DataFrame(probabilities[c])\n",
    "        if number_of_subsets == 1:\n",
    "            df = df[sample_sizes]\n",
    "            figs[c] = df.T.plot(kind='line', figsize=(10, 8), label=None, linewidth=5)\n",
    "        else:\n",
    "            figs[c] = df.plot(kind='box', figsize=(10, 8))\n",
    "        #plt.ylabel('$P_{}(\\hat{{p}}_{}(X) \\leq {} \\mid Y={})$'.format(c, c, epsilon, 1-c), fontsize=25)\n",
    "        if c == 0:\n",
    "            plt.ylabel('$TPR$', fontsize=25)\n",
    "        else:\n",
    "            plt.ylabel('$TNR$', fontsize=25)\n",
    "        plt.xlabel('$n$', fontsize=25)\n",
    "        plt.legend('', frameon=False)\n",
    "            \n",
    "    return figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:33:18.675877Z",
     "start_time": "2020-10-20T23:33:18.665501Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figs = check_asymptotic_behavior(nn_tests, datasets['E2']['samples'], datasets['E2']['labels'],\n",
    "                                number_of_subsets=1, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:48:58.910623Z",
     "start_time": "2020-10-16T03:48:58.904222Z"
    }
   },
   "outputs": [],
   "source": [
    "reports['p0_value_shrinks_for_1_fig'] = figs[0]\n",
    "reports['p1_value_shrinks_for_0_fig'] = figs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Test as a Classifier\n",
    "\n",
    "Based on the test, define the following classifier:\n",
    "$$predict_{c, \\alpha}(x)=\\begin{cases}1-c,& p_c(T(x)) \\leq \\alpha\\\\ c,& p_c(T(x)) > \\alpha \\end{cases}\\qquad \\alpha \\in [0, 1], c \\in \\{0, 1\\}$$ \n",
    "$T(x)$ is the value of the neural net's output layer when the whole pipe is fed the sample $x$ at the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:33:50.061069Z",
     "start_time": "2020-10-20T23:33:50.049534Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class OneTestClassifier(object):\n",
    "    def __init__(self, test, class_label, alpha, opposite_label=None):\n",
    "        super(OneTestClassifier, self).__init__()\n",
    "        self.test = test\n",
    "        self.class_label = class_label\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        if opposite_label is None:\n",
    "            opposite_label = 1 - class_label\n",
    "        self.opposite_label = opposite_label\n",
    "    \n",
    "    def calculate_statistic(self, samples):\n",
    "        if not(all([type(s) == list for s in samples])):\n",
    "            return self.test.calculate_statistic(samples)[0, 0]\n",
    "            \n",
    "        return np.array([self.test.calculate_statistic(sample) for sample in samples]).squeeze()\n",
    "    \n",
    "    def predict(self, samples):\n",
    "        labels = [self.class_label if self.test.p_value(sample) > self.alpha \\\n",
    "                  else self.opposite_label for sample in samples]\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:33:51.276425Z",
     "start_time": "2020-10-20T23:33:51.270404Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_clf_0 = OneTestClassifier(nn_test_0, 0, 0.05)\n",
    "nn_clf_1 = OneTestClassifier(nn_test_1, 1, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with the Original Classifier and Standard Tests of Normality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:56:23.850851Z",
     "start_time": "2020-10-21T01:56:23.844883Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:56:24.214821Z",
     "start_time": "2020-10-21T01:56:24.210342Z"
    }
   },
   "outputs": [],
   "source": [
    "class_codes = [1, 0]\n",
    "alphas = [0.01, 0.05]\n",
    "\n",
    "for class_code in class_codes:\n",
    "    test = nn_tests[class_code]\n",
    "    for alpha in alphas:\n",
    "        classifier = OneTestClassifier(test, class_code, alpha)\n",
    "        classifiers[('NN_{}'.format(class_code), alpha)] = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import standard statistical tests of normality (to be used as classifiers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:56:25.309933Z",
     "start_time": "2020-10-21T01:56:25.304462Z"
    }
   },
   "outputs": [],
   "source": [
    "for code in ['SW', 'JB', 'LF', 'AD']:\n",
    "    for alpha in alphas:\n",
    "        classifier = util.get_standard_classifier(code, alpha)\n",
    "        classifiers[(code, alpha)] = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Analysis on Set $\\mathcal{C}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:56:31.945843Z",
     "start_time": "2020-10-21T01:56:26.668529Z"
    }
   },
   "outputs": [],
   "source": [
    "n_range = range(10, 101, 10)\n",
    "metrics = ['TNR'] # Power is the true negative rate, 1 - FPR\n",
    "\n",
    "results = {}\n",
    "for group in ['C-G1', 'C-G2', 'C-G3', 'C-G4']:\n",
    "    print(group)\n",
    "    \n",
    "    samples = datasets[group]['samples'][:100]\n",
    "    labels = datasets[group]['labels'][:100]\n",
    "    \n",
    "    results[group] = {}\n",
    "    for code in classifiers:\n",
    "        print('\\t', code)\n",
    "        \n",
    "        classifier = classifiers[code]\n",
    "        results_df = util.evaluate_pretty(samples, labels, classifier, metrics=metrics, n_range=n_range, index='n')\n",
    "        results[group][code] = results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T18:21:08.734186Z",
     "start_time": "2020-09-13T18:16:44.018193Z"
    }
   },
   "source": [
    "Prepare LaTeX reports and figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-21T01:56:40.332424Z",
     "start_time": "2020-10-21T01:56:39.396987Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for group in results:\n",
    "    print(group)\n",
    "    dfs = results[group]\n",
    "    results_dict = {'{}({})'.format(*code): dfs[code]['TNR'] for code in dfs}\n",
    "    results_df = pd.concat(results_dict, axis=1)\n",
    "    results_df = results_df[sorted(results_df.columns)]\n",
    "    \n",
    "    latex = util.get_latex_table(results_df, index=True, caption=group,\n",
    "                                 label='fig:TNR_' + group)\n",
    "    reports['{}_df'.format(group)] = results_df\n",
    "    reports['{}_latex'.format(group)] = latex\n",
    "    print(latex)\n",
    "\n",
    "    df = results_df\n",
    "    df = df[[c for c in df.columns if '0.05' in c]]\n",
    "    fig = df[df.index != 'overall'].plot(kind='line', style=['o--', 'v--', '^--', 'x-', 'bD-', 'd--'],\n",
    "                                         linewidth=2,\n",
    "                                         markersize=10,\n",
    "                                         figsize=(10,8), use_index=True)\n",
    "    reports['{}_fig'.format(group)] = fig\n",
    "    #fig.legend(loc='center right', bbox_to_anchor=(1.24, 0.5), borderpad=2)\n",
    "    #latex = util.get_latex_table(df, float_format=float_format, index=True, caption='C', label='c')\n",
    "    #dbnn_storage['reports']['comparison'][group] = {'fig' : fig, 'latex': latex}\n",
    "    #print(latex)\n",
    "    \n",
    "    #plt.ylabel(ylabel, fontsize=25)\n",
    "    plt.xlabel('$n$', fontsize=25)\n",
    "    plt.legend(fontsize=20, markerscale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Overall Performance Analysis on Set $\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T07:32:08.820221Z",
     "start_time": "2020-10-17T07:32:08.814990Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = datasets['D']['samples']\n",
    "labels = datasets['D']['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the tests (actually, classifiers based on them) and create reports just as for set $\\mathcal{C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T07:38:14.896124Z",
     "start_time": "2020-10-17T07:32:10.120071Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "metrics = ['A', 'TPR', 'PPV', 'TNR', 'NPV', 'F1']\n",
    "\n",
    "for (code, alpha) in classifiers:\n",
    "    print(code, alpha)\n",
    "    classifier = classifiers[(code, alpha)]\n",
    "    print('\\tStart:', dt.datetime.now())\n",
    "    results_df = util.evaluate_pretty(samples, labels, classifier, metrics=metrics)\n",
    "    print('\\tEnd:', str(dt.datetime.now()))\n",
    "    results[(code, alpha)] = results_df\n",
    "\n",
    "print('NN')\n",
    "results[('NN', '')] = util.evaluate_pretty(samples, labels, dbnn, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:15:07.623211Z",
     "start_time": "2020-10-17T14:15:07.594541Z"
    }
   },
   "outputs": [],
   "source": [
    "df_report = pd.concat(results)\n",
    "#df_report.index=pd.MultiIndex.from_tuples([(x[0], x[1]) for x in df_report.index])\n",
    "\n",
    "keys = sorted([x for x in results.keys() if x[0] != 'NN']) + [('NN', '')]\n",
    "df_report = pd.concat({x : results[x] for x in keys})\n",
    "\n",
    "display(df_report)\n",
    "\n",
    "latex = util.get_latex_table(df_report, index=True, caption='C', label='x')\n",
    "print(latex)\n",
    "\n",
    "reports['D__df'] = df_report\n",
    "reports['D_latex'] = latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:10:34.552928Z",
     "start_time": "2020-10-17T14:04:36.090282Z"
    }
   },
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for code in classifiers:\n",
    "    print(code)\n",
    "    classifier = classifiers[code]\n",
    "    df = util.evaluate_pretty(samples, labels, classifier, metrics=metrics, n_range=range(10, 101, 10))\n",
    "    dfs[code] = df\n",
    "    reports['D_{}_df'.format(code)] = df\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:10:34.767196Z",
     "start_time": "2020-10-17T14:10:34.554343Z"
    }
   },
   "outputs": [],
   "source": [
    "df_report_1 = pd.concat({code:dfs[code][['TPR']].set_index(dfs[code]['n']) for code in dfs\n",
    "          if code[0] != 'DBNN_0'}, axis=1)\n",
    "display(df_report_1)\n",
    "latex = util.get_latex_table(df_report_1, index=True, caption='C', label='L')\n",
    "\n",
    "reports['D_combined_df'] = df_report_1\n",
    "reports['D_combined_latex'] = latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AUROC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:04:47.195844Z",
     "start_time": "2020-10-16T02:46:52.660Z"
    }
   },
   "outputs": [],
   "source": [
    "aurocs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-16T03:04:47.196541Z",
     "start_time": "2020-10-16T02:46:53.102Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = datasets['D']['samples']\n",
    "labels = datasets['D']['labels']\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "styles = ['dotted', 'dashed', 'dashdot', (0, (3, 5, 1, 5, 1, 5))] \n",
    "styles = styles * 3\n",
    "\n",
    "statistics = {\n",
    "    code[0] : classifiers[code].calculate_statistic for code in classifiers if 'IB' not in code[0]\n",
    "}\n",
    "\n",
    "# NN_1 and NN_0 have the same ROC-curve as NN\n",
    "del statistics['NN_1']\n",
    "del statistics['NN_0']\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "for clf_code in statistics:\n",
    "    print(clf_code)\n",
    "    \n",
    "    # Compute the scores\n",
    "    statistic_function = statistics[clf_code]\n",
    "    scores = statistic_function(samples)\n",
    "    \n",
    "    # Invert the statistics of the tests which treat higher values as stronger indicators\n",
    "    # of non-normality\n",
    "    if clf_code in ['LF', 'JB', 'AD']:\n",
    "        scores = -scores\n",
    "    \n",
    "    # Make sure no non-finite values are present in the array of scores\n",
    "    mask = np.isfinite(np.array(scores))\n",
    "    filtered_labels = np.array(labels)[mask]\n",
    "    filtered_scores = np.array(scores)[mask]\n",
    "    \n",
    "    # Plot the curves\n",
    "    fpr, tpr, tr = sklearn.metrics.roc_curve(filtered_labels, filtered_scores, pos_label=1)\n",
    "    plt.plot(fpr, tpr, linestyle=styles.pop(0), linewidth=3, label=clf_code)\n",
    "    aurocs[clf_code] = sklearn.metrics.roc_auc_score(filtered_labels, filtered_scores)\n",
    "\n",
    "# Show the neural network's curve\n",
    "prepared_input = prepare_input(samples, dbnn)\n",
    "probabilities = dbnn['neural_net'].predict_proba(prepared_input)\n",
    "scores = probabilities[:, 1]\n",
    "print('NN')\n",
    "fpr, tpr, tr = sklearn.metrics.roc_curve(labels, scores, pos_label=1)\n",
    "plt.plot(fpr, tpr, linestyle=styles.pop(0), linewidth=3, label='DBNN')\n",
    "aurocs['NN'] = sklearn.metrics.roc_auc_score(labels, scores)\n",
    "\n",
    "print(aurocs)\n",
    "\n",
    "plt.xlabel('FPR', fontsize=16)\n",
    "plt.ylabel('TPR', fontsize=16)\n",
    "plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T12:53:35.053112Z",
     "start_time": "2020-09-07T12:53:35.045880Z"
    }
   },
   "source": [
    "Save the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T23:46:38.434766Z",
     "start_time": "2020-10-20T23:46:35.272510Z"
    }
   },
   "outputs": [],
   "source": [
    "traverse_and_save({ 'nn' : {'derived_tests' : reports}}, 'reports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T17:42:44.039471Z",
     "start_time": "2020-10-17T17:42:43.820951Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('reports.p', 'wb') as f:\n",
    "    pickle.dump(reports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p3normal",
   "language": "python",
   "name": "p3normal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "434.667px",
    "left": "416px",
    "top": "109.9px",
    "width": "212.067px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
